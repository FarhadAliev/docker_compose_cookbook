#------------------------------------------------------------------------------
# Copyright 2019 Robert Cowart
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

version: '3'
networks:
  kafka:
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.3.0-1
    container_name: zookeeper
    restart: 'no'
    hostname: zookeeper
    networks:
      - kafka
    ports:
      # Client
      - 2181:2181/tcp
      # Peer
      - 2888:2888/tcp
      # Leader
      - 3888:3888/tcp
      # JMX
      - 10020:10020/tcp
    volumes:
      - /var/lib/zookeeper/data:/var/lib/zookeeper/data
      - /var/lib/zookeeper/log:/var/lib/zookeeper/log
      - /var/log/zookeeper:/var/log/zookeeper
    environment:
      # JVM heap size.
      KAFKA_HEAP_OPTS: '-Xms512m -Xmx512m'
      
      # JMX Settings.
      KAFKA_JMX_HOSTNAME: 0.0.0.0
      KAFKA_JMX_PORT: 10020
      #KAFKA_JMX_OPTS: '-Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote=true  -Dcom.sun.management.jmxremote.port=10020 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false'
      
      # The directory where ZooKeeper logs will be stored.
      LOG_DIR: /var/log/zookeeper
      
      # The directory where ZooKeeper data will be stored.
      ZOOKEEPER_DATA_DIR: /var/lib/zookeeper
      
      # the port at which the clients will connect
      ZOOKEEPER_CLIENT_PORT: 2181
      
      # The number of milliseconds of each tick
      ZOOKEEPER_TICK_TIME: 2000
      
      # The number of ticks that the initial synchronization phase can take
      ZOOKEEPER_INIT_LIMIT: 5
      
      # The number of ticks that can pass between sending a request and getting an acknowledgement
      ZOOKEEPER_SYNC_LIMIT: 2
      
      # Limits the number of concurrent connections (at the socket level) that a single client, identified by IP address, may make to a single member of the ZooKeeper ensemble. Defaults to 60. Disabled is 0.
      ZOOKEEPER_MAX_CLIENT_CNXNS: 0
      
      # The id must be unique within the ensemble and should have a value between 1 and 255.
      ZOOKEEPER_SERVER_ID: 1
      
      # A list of machines of the Zookeeper ensemble.
      ZOOKEEPER_SERVERS: zookeeper:2888:3888

  kafka:
    image: confluentinc/cp-kafka:5.3.0-1
    container_name: kafka
    depends_on:
      - zookeeper
    restart: 'no'
    hostname: kafka
    networks:
      - kafka
    ports:
      # kafka broker listener
      - 9092:9092/tcp
      # JMX
      - 10030:10030/tcp
    volumes:
      - /var/lib/kafka/data:/var/lib/kafka/data
      - /var/log/kafka:/var/log/kafka
    environment:
      # JVM heap size.
      KAFKA_HEAP_OPTS: '-Xms1g -Xmx1g'

      # JMX Settings.
      KAFKA_JMX_HOSTNAME: 0.0.0.0
      KAFKA_JMX_PORT: 10030
      #KAFKA_JMX_OPTS: '-Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=10030 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false'

      # A comma seperated list of directories under which to store log files
      LOG_DIR: /var/log/kafka

      # The directory where ZooKeeper data will be stored.
      KAFKA_DATA_DIR: /var/lib/kafka

      # Listeners to publish to ZooKeeper for clients to use, if different than the listeners config property. In IaaS
      # environments, this may need to be different from the interface to which the broker binds. If this is not set,
      # the value for listeners will be used. Unlike listeners it is not valid to advertise the 0.0.0.0 meta-address.
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092

      # The broker id for this server. If unset, a unique broker id will be generated. To avoid conflicts between
      # zookeeper generated broker id's and user configured broker id's, generated broker ids start from
      # reserved.broker_MAX_id + 1.
      KAFKA_BROKER_ID: 0

      # If set to true, and confluent-support-metrics package is installed then the feature to collect and report
      # support metrics ("Metrics") is enabled.
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'

      # Default replication factors for automatically created topics.
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1

      # Enables delete topic. Delete topic through the admin tool will have no effect if this config is turned off.
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      
      # The address the socket server listens on. If changed, the docker-compose port configuration will also need to
      # be changed.
      KAFKA_LISTENERS: PLAINTEXT://:9092

      # The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property.
      KAFKA_LOG_RETENTION_HOURS: 168

      # When a producer sets acks to "all" (or "-1"), min.insync.replicas specifies the minimum number of replicas that
      # must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the
      # producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used
      # together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario
      # would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks
      # of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a
      # write.
      KAFKA_MIN_INSYNC_REPLICAS: 1

      # The default number of log partitions per topic.
      KAFKA_NUM_PARTITIONS: 3

      # After a consumer group loses all its consumers (i.e. becomes empty) its offsets will be kept for this retention
      # period before getting discarded. For standalone consumers (using manual assignment), offsets will be expired
      # after the time of last commit plus this retention period.
      KAFKA_OFFSETS_RETENTION_MINUTES: 10080

      # The number of partitions for the offset commit topic, "__consumer_offsets" (should not change after deployment)
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 12

      # The replication factor for the offsets topic, "__consumer_offsets"  (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

      # Overridden min.insync.replicas config for the transaction topic.
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # The number of partitions for the transaction topic, "__transaction_state" (should not change after deployment).
      KAFKA_TRANSACTION_STATE_LOG_NUM_PARTITIONS: 12

      # The replication factor for the transaction topic, "__transaction_state"  (set higher to ensure availability).
      # Internal topic creation will fail until the cluster size meets this replication factor requirement.
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

      # The maximum amount of time in ms that the transaction coordinator will wait before proactively expire a
      # producer's transactional id without receiving any transaction status updates from it.
      KAFKA_TRANSACTIONAL_ID_EXPIRATION_MS: 604800000

      # Specifies the ZooKeeper connection string in the form hostname:port where host and port are the host and port
      # of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down
      # you can also specify multiple hosts in the form hostname1:port1,hostname2:port2,hostname3:port3. The server can
      # also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some
      # path in the global ZooKeeper namespace. For example to give a chroot path of /chroot/path you would give the
      # connection string as hostname1:port1,hostname2:port2,hostname3:port3/chroot/path.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

  kafka_manager:
    image: hlebalbau/kafka-manager:2.0.0.2
    container_name: kafka-manager
    depends_on:
      - zookeeper
    restart: 'no'
    hostname: kafka-manager
    networks:
      - kafka
    ports:
      - 9000:9000/tcp
    environment:
      ZK_HOSTS: zookeeper:2181
      APPLICATION_SECRET: secret
    command: -Dpidfile.path=/dev/null

  zoonavigator-api:
    image: elkozmon/zoonavigator-api:0.6.1
    container_name: zoonavigator-api
    depends_on:
      - zookeeper
    restart: 'no'
    hostname: zoonavigator-api
    network_mode: bridge
    networks:
      - kafka
    ports:
      - 9009:9009/tcp
    environment:
      ### API Server Settings

      # Tells the HTTP server which port to bind to. To disable HTTP set this variable to disabled.
      API_HTTP_PORT: 9009

      # If set, HTTPS server will bind to this port.
      #API_HTTPS_PORT: 9443

      # The path to the keystore containing the private key and certificate, if not provided generates a keystore for
      # you.
      # API_SSL_KEYSTORE_PATH: 

      # The password to the keystore, defaults to a blank password.
      #API_SSL_KEYSTORE_PASSWORD: 

      # The key store type.
      #API_SSL_KEYSTORE_TYPE: 

      # Sets session inactivity timeout for users. This value is in milliseconds.
      # default: 900000
      #API_SESSION_TIMEOUT_MILLIS: 900000

      # Secret key for Play Framework - used for signing session cookies and CSRF tokens.
      # Defaults to 64 random characters generated from /dev/urandom.
      #API_SECRET: 



      ### Java Settings

      # Custom Java arguments.
      #JAVA_OPTS: 

      # Sets initial Java heap size. This value is in bytes if no unit is specified.
      #JAVA_XMS: 

      # Sets maximum Java heap size. This value is in bytes if no unit is specified.
      #JAVA_XMX: 

      # Path to JAAS login configuration file to use.
      #JAVA_JAAS_LOGIN_CONFIG

      # If set to true, enables debugging mode and detailed logging for Kerberos.
      #JAVA_KRB5_DEBUG

      # Sets the default Kerberos realm.
      #JAVA_KRB5_REALM

      # Sets the default Kerberos KDC.
      #JAVA_KRB5_KDC



      ### Zookeeper Client Settings

      # Sets inactivity timeout for ZooKeeper client. If user doesn’t make any request during this period ZooKeeper
      # connection will be closed and recreated for the future request if any. Note that user does not get logged out
      # unlike in event of session timeout. This value is in milliseconds.
      # default: 5000
      #ZK_CLIENT_TIMEOUT_MILLIS: 5000

      # Sets timeout for attempt to establish connection with ZooKeeper. This value is in milliseconds.
      # default: 5000
      #ZK_CONNECT_TIMEOUT_MILLIS: 5000

      # Set the value to false to disable SASL authentication.
      # default: true
      ZK_SASL_CLIENT: "false"

      # Specifies the context key in the JAAS login file.
      # default: Client
      #ZK_SASL_CLIENT_CONFIG: Client

      # Specifies the primary part of the server principal. Learn more here.
      # default: zookeeper
      #ZK_SASL_CLIENT_USERNAME: zookeeper

      # Realm part of the server principal. By default it is the client principal realm.
      #ZK_SERVER_REALM: 

      # If you want to connect to the server secure client port, you need to set this property to true. This will
      # connect to server using SSL with specified credentials. Note that it requires using the Netty client.
      #ZK_CLIENT_SECURE: 

      # Specifies which ClientCnxnSocket to be used. If you want to connect to server’s secure client port, you need to
      # set this property to: org.apache.zookeeper.ClientCnxnSocketNetty.
      # default: org.apache.zookeeper.ClientCnxnSocketNIO
      #ZK_CLIENT_CNXN_SOCKET: org.apache.zookeeper.ClientCnxnSocketNIO

      # Specifies the file path to a JKS containing the local credentials to be used for SSL connections.
      #ZK_SSL_KEYSTORE_PATH: 

      # Specifies the password to a JKS containing the local credentials to be used for SSL connections.
      #ZK_SSL_KEYSTORE_PASSWORD: 

      # Specifies the file path to a JKS containing the remote credentials to be used for SSL connections.
      #ZK_SSL_TRUSTSTORE_PATH: 

      # Specifies the password to a JKS containing the remote credentials to be used for SSL connections.
      #ZK_SSL_TRUSTSTORE_PASSWORD: 

  zoonavigator-web:
    image: elkozmon/zoonavigator-web:0.6.1
    container_name: zoonavigator-web
    depends_on:
      - zoonavigator-api
    restart: 'no'
    hostname: zoonavigator-web
    networks:
      - kafka
    ports:
      - 8000:8000/tcp
    environment:
      # Tells the HTTP server which port to bind to.
      # default: 8000
      WEB_HTTP_PORT: 8000

      # Specifies the host where ZooNavigator API runs.
      # default: api
      API_HOST: zoonavigator-api

      # Specifies the port where ZooNavigator API runs.
      # default: 9000
      API_PORT: 9009

      # Sets the timeout on requests to the ZooNavigator API. This value is in milliseconds.
      # default: 10000
      API_REQUEST_TIMEOUT_MILLIS: 10000

      # If set to true, tells web server to bind to all IPv6 addresses.
      # default: false
      #ENABLE_IPV6: "false"

      # If set, ZooNavigator will use this value as a default connection string and skip the connect form,
      # automatically connecting to listed ZooKeeper servers.
      AUTO_CONNECT_CONNECTION_STRING: zookeeper:2181

      # In addition to presetting connection string as explained above, you can also set Auth info which ZooNavigator
      # will use to authenticate with ZooKeeper during the auto-connect. Use semicolon (;) to separate multiple
      # entries.
      #AUTO_CONNECT_AUTH_INFO: 
